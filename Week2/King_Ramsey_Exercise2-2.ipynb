{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Ramsey King\n",
    "# DSC 550 - Data Mining\n",
    "# September 11, 2021\n",
    "# Week 2: Handling Categorical Data, Text, Dates & Times\n",
    "# Exercise 2.2 \n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "You can find the dataset controversial-comments.jsonl for this exercise in the Weekly Resources: Week 2 Data Files.\n",
    "Pre-processing Text: For this part, you will start by reading the controversial-comments.jsonl file into a DataFrame."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "comments_df = pd.read_json('controversial-comments.jsonl', lines=True)\n",
    "comments_df.head()\n",
    "\n"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": "   con                                                txt\n0    0  Well it's great that he did something about th...\n1    0                       You are right Mr. President.\n2    0  You have given no input apart from saying I am...\n3    0  I get the frustration but the reason they want...\n4    0  I am far from an expert on TPP and I would ten...",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>con</th>\n      <th>txt</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>Well it's great that he did something about th...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0</td>\n      <td>You are right Mr. President.</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0</td>\n      <td>You have given no input apart from saying I am...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0</td>\n      <td>I get the frustration but the reason they want...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0</td>\n      <td>I am far from an expert on TPP and I would ten...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "A. Convert all text to lowercase letters."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "source": [
    "comments_df['txt'] = comments_df['txt'].apply(str.lower)\n",
    "comments_df['txt'][:5]"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": "0    well it's great that he did something about th...\n1                         you are right mr. president.\n2    you have given no input apart from saying i am...\n3    i get the frustration but the reason they want...\n4    i am far from an expert on tpp and i would ten...\nName: txt, dtype: object"
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "B. Remove all punctuation from the text.\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "source": [
    "import re\n",
    "comments_df['txt'] = comments_df['txt'].apply(lambda remove_punct: re.sub(r'[^\\w\\s]', '', remove_punct))\n",
    "comments_df['txt'][:5]"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": "0    well its great that he did something about tho...\n1                           you are right mr president\n2    you have given no input apart from saying i am...\n3    i get the frustration but the reason they want...\n4    i am far from an expert on tpp and i would ten...\nName: txt, dtype: object"
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "C. Remove stop words.\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "# nltk.download('stopwords')\n",
    "stop_words = stopwords.words('english')\n",
    "\n",
    "def rem_stop_words(rem_list):\n",
    "    return [word for word in rem_list if word not in stop_words]\n",
    "\n",
    "\n",
    "'''\n",
    "# THIS CODE WAS USED TO MAKE SURE THAT THE FUNCTIONS WORKED BEFORE RUNNING IT ON THE ENTIRE DATAFRAME\n",
    "comments_df_test = comments_df[:10].copy()\n",
    "comments_df_test['txt_tokenized'] = comments_df_test['txt'].apply(word_tokenize)\n",
    "print(comments_df_test['txt_tokenized'][:5])\n",
    "comments_df_test['txt_tokenized'] = comments_df_test['txt_tokenized'].apply(rem_stop_words)\n",
    "comments_df_test['txt_tokenized'][:5]\n",
    "'''\n",
    "comments_df['txt_tokenized'] = comments_df['txt'].apply(word_tokenize)\n",
    "comments_df['txt_tokenized'] = comments_df['txt_tokenized'].apply(rem_stop_words)\n",
    "comments_df['txt_tokenized'][:5]"
   ],
   "outputs": [],
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "D. Apply NLTKâ€™s PorterStemmer."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "from nltk.stem.porter import PorterStemmer\n",
    "porter = PorterStemmer()\n",
    "\n",
    "def apply_porter_stemmer(tokenized_words):\n",
    "    return [porter.stem(word) for word in tokenized_words]\n",
    "\n",
    "comments_df['txt_tokenized_stemmed'] = comments_df['txt_tokenized'].apply(apply_porter_stemmer)\n",
    "comments_df['txt_tokenized_stemmed'][:5]"
   ],
   "outputs": [],
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Now that the data is pre-processed, you will apply three different techniques to get it into a usable form for\n",
    "model-building. Apply each of the following steps (individually) to the pre-processed data.\n",
    "\n",
    "A. Convert each text entry into a word-count vector (see sects 5.3 & 6.8 in the Machine Learning with Python Cookbook)."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "count = CountVectorizer()\n",
    "comments_df['word_count_vect'] = list(comments_df['txt'])\n",
    "comments_df['word_count_vect'] = comments_df['word_count_vect'].apply(count.fit_transform)\n",
    "comments_df['word_count_vect'][:5]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "B. Convert each text entry into a part-of-speech tag vector (see section 6.7 in the Machine Learning with Python Cookbook)."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "C. Convert each entry into a term frequency-inverse document frequency (tfidf) vector\n",
    "(see section 6.9 in the Machine Learning with Python Cookbook)."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "For the three techniques in problem (2) above, give an example where each would be useful."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.7.6",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3"
  },
  "interpreter": {
   "hash": "bf60427b139290154779a7e38fd0f127f78e5a9dfc17b4a4bd1d849158c5fa70"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}