{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Ramsey King\r\n",
    "# DSC 550 - Data Mining\r\n",
    "# September 18, 2021\r\n",
    "# Exercise 3.2"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Load the data file DailyComments.csv from the Week 4 Data Files into a data frame.\r\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "source": [
    "import pandas as pd\r\n",
    "import numpy as np\r\n",
    "\r\n",
    "daily_df = pd.read_csv('DailyComments.csv')\r\n",
    "daily_df.head(7)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Day of Week</th>\n",
       "      <th>comments</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Monday</td>\n",
       "      <td>Hello, how are you?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Tuesday</td>\n",
       "      <td>Today is a good day!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Wednesday</td>\n",
       "      <td>It's my birthday so it's a really special day!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Thursday</td>\n",
       "      <td>Today is neither a good day or a bad day!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Friday</td>\n",
       "      <td>I'm having a bad day.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Saturday</td>\n",
       "      <td>There' s nothing special happening today.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Sunday</td>\n",
       "      <td>Today is a SUPER good day!</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Day of Week                                        comments\n",
       "0      Monday                             Hello, how are you?\n",
       "1     Tuesday                            Today is a good day!\n",
       "2   Wednesday  It's my birthday so it's a really special day!\n",
       "3    Thursday       Today is neither a good day or a bad day!\n",
       "4      Friday                           I'm having a bad day.\n",
       "5    Saturday       There' s nothing special happening today.\n",
       "6      Sunday                      Today is a SUPER good day!"
      ]
     },
     "metadata": {},
     "execution_count": 83
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Identify a scheme to categorize each comment as positive or negative. You can devise your own scheme or find a commonly used scheme to perform this sentiment analysis. However you decide to do this, make sure to explain the scheme you decide to use.\r\n",
    "Implement your sentiment analysis with code and display the results. Note: DailyComments.csv is a purposely small file, so you will be able to clearly see why the results are what they are.\r\n",
    "For up to 5% extra credit, find another set of comments, e.g., some tweets, and perform the same sentiment analysis."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "source": [
    "import nltk\r\n",
    "# words = [w.lower().split() for w in daily_df.comments if w]\r\n",
    "# words\r\n",
    "\r\n",
    "tokenizer = nltk.RegexpTokenizer(r\"\\w+\")\r\n",
    "words = [tokenizer.tokenize(w) for w in daily_df.comments]\r\n",
    "words\r\n"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[['Hello', 'how', 'are', 'you'],\n",
       " ['Today', 'is', 'a', 'good', 'day'],\n",
       " ['It',\n",
       "  's',\n",
       "  'my',\n",
       "  'birthday',\n",
       "  'so',\n",
       "  'it',\n",
       "  's',\n",
       "  'a',\n",
       "  'really',\n",
       "  'special',\n",
       "  'day'],\n",
       " ['Today', 'is', 'neither', 'a', 'good', 'day', 'or', 'a', 'bad', 'day'],\n",
       " ['I', 'm', 'having', 'a', 'bad', 'day'],\n",
       " ['There', 's', 'nothing', 'special', 'happening', 'today'],\n",
       " ['Today', 'is', 'a', 'SUPER', 'good', 'day']]"
      ]
     },
     "metadata": {},
     "execution_count": 84
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "source": [
    "stopwords = nltk.corpus.stopwords.words('english')\r\n",
    "# print(stopwords)\r\n",
    "for i in range(len(words)):\r\n",
    "    words[i] = [w.lower() for w in words[i] if w not in stopwords ]\r\n",
    "\r\n",
    "words"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[['hello'],\n",
       " ['today', 'good', 'day'],\n",
       " ['it', 'birthday', 'really', 'special', 'day'],\n",
       " ['today', 'neither', 'good', 'day', 'bad', 'day'],\n",
       " ['i', 'bad', 'day'],\n",
       " ['there', 'nothing', 'special', 'happening', 'today'],\n",
       " ['today', 'super', 'good', 'day']]"
      ]
     },
     "metadata": {},
     "execution_count": 85
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "source": [
    "words_single = []\r\n",
    "for i in range(len(words)):\r\n",
    "    words_single.append(' '.join(words[i]))\r\n",
    "words_single\r\n",
    "\r\n",
    "words_string = ' '.join(words_single)\r\n",
    "words_string = words_string.split(' ')\r\n",
    "words_string\r\n",
    "fd = nltk.FreqDist(words_string)\r\n",
    "fd.most_common(3)\r\n",
    "fd.tabulate(3)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "  day today  good \n",
      "    6     4     3 \n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "source": [
    "# nltk.download('vader_lexicon')\r\n",
    "from nltk.sentiment import SentimentIntensityAnalyzer\r\n",
    "sia = SentimentIntensityAnalyzer()\r\n",
    "\r\n",
    "# daily_df['comments'] = daily_df['comments'].str.lower()\r\n",
    "# daily_df['comments'] = daily_df['comments'].str.replace(r'[^\\w\\s]+', '', regex=True)\r\n",
    "\r\n",
    "for i in range(len(daily_df.comments)):\r\n",
    "    print(daily_df['comments'][i], sia.polarity_scores(daily_df['comments'][i]))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Hello, how are you? {'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound': 0.0}\n",
      "Today is a good day! {'neg': 0.0, 'neu': 0.484, 'pos': 0.516, 'compound': 0.4926}\n",
      "It's my birthday so it's a really special day! {'neg': 0.0, 'neu': 0.664, 'pos': 0.336, 'compound': 0.5497}\n",
      "Today is neither a good day or a bad day! {'neg': 0.508, 'neu': 0.492, 'pos': 0.0, 'compound': -0.735}\n",
      "I'm having a bad day. {'neg': 0.538, 'neu': 0.462, 'pos': 0.0, 'compound': -0.5423}\n",
      "There' s nothing special happening today. {'neg': 0.361, 'neu': 0.639, 'pos': 0.0, 'compound': -0.3089}\n",
      "Today is a SUPER good day! {'neg': 0.0, 'neu': 0.277, 'pos': 0.723, 'compound': 0.8327}\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Textblob and SpaCy"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "from textblob import TextBlob\r\n",
    "\r\n",
    "blob = daily_df['comments'][0]\r\n",
    "blob.sentiment"
   ],
   "outputs": [
    {
     "output_type": "error",
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'textblob'",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-0516dfe41bf6>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mtextblob\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mTextBlob\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mblob\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdaily_df\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'comments'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mblob\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msentiment\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'textblob'"
     ]
    }
   ],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.7.6",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.7.6 64-bit ('base': conda)"
  },
  "interpreter": {
   "hash": "bf60427b139290154779a7e38fd0f127f78e5a9dfc17b4a4bd1d849158c5fa70"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}